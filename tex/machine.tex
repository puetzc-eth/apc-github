% Introduction to Machine-Learning (1 week)

%\lstinputlisting[language=C++]{src/intro/test.cpp}

The idea behind \emph{supervised machine learning} is to determine a function from a set of training data that can be used to predict the output of new data. The training data is a representative set of examples with input values (typically a vector) and a known output value. Typical machine learning tasks are, for example, \emph{classifications} (discrete output: for example, a molecule is biologically active or not) or \emph{regressions} (continuous output: for example, linear regression).

\begin{center}\includegraphics[width=0.65\textwidth]{img/machine/MachineGeneralScheme.png}\end{center}

The following methods, among others, can be used for this purpose:

\begin{itemize}
    \item Linear models, e.g. linear regression, logistic regression
    \item Decision tree
    \item Random forest
    \item Gradient tree boosting
    \item Na√Øve Bayes
    \item Support vector machines (SVM)
    \item Artificial neural networks
\end{itemize}

\paragraph{Validation}
Once a function has been determined from the training data, it still needs to be validated, since the training data for such algorithms is often too small and there is a risk of overfitting the training data, whereby the function performs well on the training set but not well on new data. Typical validation techniques are \emph{train/test split} or \emph{K-fold cross-validation}.

\begin{center}\includegraphics[width=0.65\textwidth]{img/machine/MachineOverUnderFiting.png}\end{center}

For classification models, slightly different assessment criteria for the quality of an ML-model must be applied, such as the \emph{receiver-operator curve} (ROC), in which the true positive rate is plotted against the false positive rate. Depending on the error rates, further metrices for classification models can be calculated.

\begin{center}\includegraphics[width=0.45\textwidth]{img/machine/MachineRocCurve.png}\includegraphics[width=0.45\textwidth]{img/machine/MachineClassificationMetrices.png}\end{center}

\subsection{Linear models: linear regression, logistic regression}

\paragraph{Linear Regression}
Linear regression is the simplest ML-model and has as training data a set of example values of $(x,y)$ values, where the input values are the $x$ values and the output values (continues) are the $y$ values. The goal of the regression is to find a linear function $y(x)=ax+b$ for which the squared distances of the points from the regression line are minimized. 

\begin{center}\includegraphics[width=0.65\textwidth]{img/machine/MachineLinearRegression.png}\end{center}

\paragraph{Logistic Regression}
In logistic regression (similar to multiple linear regression), an input vector $X_i=(x_{1,i}, x_{2,i},\cdots,x_{N,i})$ is compared to a discrete output value $Y$ (here either 0 or 1, but generally classification) as training data. The coefficients $(a_1,a_2,\cdots,a_N)$ are fitted for a logistic function, where $p_i$ is the probability for a $y$-value. These models are often relatively simple but very effective.

\begin{align}
    \log_{2}\left(\frac{p_i}{1-p_i}\right)=a_0+a_1x_{1,i}+\cdots+a_Nx_{N,i}
\end{align}

\begin{center}\includegraphics[width=0.65\textwidth]{img/machine/MachineLogisticRegression.png}\end{center}

\subsection{Decision trees}

\emph{Decision trees} can be used in machine learning for both classifications and regressions. They use as training data as input variable vectors with multiple attributes and as output variables integer or continuous values. The attributes of the input vector determine which branch of the decision tree is taken.

\begin{center}\includegraphics[width=0.85\textwidth]{img/machine/MachineDecisionTrees.png}\end{center}



\subsection{Ensemble methods}

\subsection{Artificial neural networks}

\subsection{Practical considerations}